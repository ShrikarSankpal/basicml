{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\E\\Study\\Projects\\basicml\\scripts\\inference\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "pickle_model = os.path.abspath(current_dir+\"./../../resources/model.pkl\")\n",
    "input_file = os.path.abspath(current_dir+\"./../../data/inference/input_file.dat\")\n",
    "output_file = os.path.abspath(current_dir+\"./../../data/inference/output_file.dat\")\n",
    "combined_csv_file = os.path.abspath(current_dir+\"./../../data/inference/combined_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(pickle_model, 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'contamination': 0.056,\n",
       " 'max_features': 2,\n",
       " 'max_samples': 'auto',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file,\"r\") as f:\n",
    "\tnumbers = [line.strip().split(\",\") for line in f]\n",
    "\t#print(\"numbers: \",numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def business_rule_anomaly(row,feature1_bounds,feature2_bounds):\n",
    "    f1 = row['column1']\n",
    "    f2 = row['column2']\n",
    "\n",
    "    if(f1>feature1_bounds[1] or f1<feature1_bounds[0] or f2>feature2_bounds[1] or f2<feature2_bounds[0]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def business_rule_nonanomaly(row,feature1_bounds,feature2_bounds):\n",
    "    f1 = row['column1']\n",
    "    f2 = row['column2']\n",
    "\n",
    "    if(f1<=feature1_bounds[1] and f1>=feature1_bounds[0] and f2<=feature2_bounds[1] and f2>=feature2_bounds[0]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def populate_final_result(row):\n",
    "    if(row['business_rule_anomaly']==-1):\n",
    "        return \"Anomaly: Business\"\n",
    "    elif(row['business_rule_nonanomaly']==-1):\n",
    "        return \"NonAnomaly: Business\"\n",
    "    elif(row['predictions']==-1):\n",
    "        return \"Anomaly: ML\"\n",
    "    elif(row['predictions']==1):\n",
    "        return \"NonAnomaly: ML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#create a daraframe\n",
    "df = pd.DataFrame(numbers, columns=['column1','column2'])\n",
    "df['column1'] = df['column1'].astype('float')\n",
    "df['column2'] = df['column2'].astype('float')\n",
    "\n",
    "#Apply abs anomaly business logic\n",
    "feature1_anomaly_bounds=[0,8]\n",
    "feature2_anomaly_bounds=[0,8]\n",
    "feature1_nonanomaly_bounds=[0,1.5]\n",
    "feature2_nonanomaly_bounds=[0,1.5]\n",
    "\n",
    "df['business_rule_anomaly'] = df.apply(business_rule_anomaly,axis=1,feature1_bounds=feature1_anomaly_bounds, feature2_bounds=feature2_anomaly_bounds)\n",
    "df['business_rule_nonanomaly'] = df.apply(business_rule_nonanomaly,axis=1,feature1_bounds=feature1_nonanomaly_bounds, feature2_bounds=feature2_nonanomaly_bounds)\n",
    "\n",
    "# Apply ML logic\n",
    "predictions = loaded_model.predict(df.loc[:,['column1','column2']].values).tolist()\n",
    "df['predictions'] = predictions\n",
    "\n",
    "df['final'] = df.apply(populate_final_result,axis=1)\n",
    "df.to_csv(combined_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file,\"w\") as f:\n",
    "\tfor result in predictions:\n",
    "\t\tf.write(str(result)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
